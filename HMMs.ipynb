{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSE 5525 Lab 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7eqsaqQwFMm"
      },
      "source": [
        "Group 14: Naveen Makkar, Neel Mansukhani, Tze Hei Tam, Xuecheng Liu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21zwbESWNVak"
      },
      "source": [
        "# Imports\r\n",
        "import math\r\n",
        "import numpy as np\r\n",
        "from collections import Counter\r\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Risv0rnq04dj"
      },
      "source": [
        "# Part 0: Viterbi\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ss1HaEB0WIM"
      },
      "source": [
        "Note: Need to upload data to runtime before running."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNWXjSIfzKqw"
      },
      "source": [
        "# Compute counts from train data\r\n",
        "\r\n",
        "# Initialize data structures\r\n",
        "tag_given_tag_counts=dict()\r\n",
        "word_given_tag_counts=dict()\r\n",
        "\r\n",
        "tag_count = dict({'<s>': 0})\r\n",
        "\r\n",
        "unique_words = set()\r\n",
        "\r\n",
        "with open (\"pos_train.txt\",\"r\") as infile:\r\n",
        "    for line in infile:\r\n",
        "        #\r\n",
        "        # first tag is the start symbol\r\n",
        "        lasttag=[\"<s>\"]\r\n",
        "\r\n",
        "        tag_count['<s>'] += 1\r\n",
        "        #\r\n",
        "        # split line into word/tag pairs\r\n",
        "        #\r\n",
        "        for wordtag in line.rstrip().split(\" \"):\r\n",
        "            if wordtag == \"\":\r\n",
        "                continue\r\n",
        "            # note that you might have escaped slashes\r\n",
        "            # 1\\/2/CD means \"1/2\" \"CD\"\r\n",
        "            # keep 1/2 as 1\\/2 \r\n",
        "            parts=wordtag.split(\"/\")\r\n",
        "            pre_tag=parts.pop()\r\n",
        "            word=\"/\".join(parts)\r\n",
        "\r\n",
        "            tag_parts = pre_tag.split(\"|\")\r\n",
        " \r\n",
        "            for tag in tag_parts:\r\n",
        "              #\r\n",
        "              # update counters\r\n",
        "              if tag not in word_given_tag_counts:\r\n",
        "                  word_given_tag_counts[tag]=Counter()\r\n",
        "\r\n",
        "              if tag not in tag_count:\r\n",
        "                tag_count[tag] = 0\r\n",
        "\r\n",
        "              tag_count[tag] += 1\r\n",
        "\r\n",
        "              word_given_tag_counts[tag][word]+=1\r\n",
        "\r\n",
        "            for prev_tag in lasttag:\r\n",
        "              if prev_tag not in tag_given_tag_counts:\r\n",
        "                  tag_given_tag_counts[prev_tag]=Counter()\r\n",
        "\r\n",
        "            # Update list of words \r\n",
        "            unique_words.add(word)\r\n",
        "\r\n",
        "            for tag in tag_parts:\r\n",
        "              for prev_tag in lasttag:\r\n",
        "                tag_given_tag_counts[prev_tag][tag]+=1\r\n",
        "\r\n",
        "\r\n",
        "            lasttag=tag_parts\r\n",
        "\r\n",
        "# Create lists for words and tags, start tag not included\r\n",
        "tags = list(word_given_tag_counts.keys())\r\n",
        "unique_words = list(unique_words)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WecwlNU9ax8K"
      },
      "source": [
        "The above block of code reads in the training data and processes it. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hw19grLf1Azd"
      },
      "source": [
        "# Read in test data\r\n",
        "\r\n",
        "# Initialize data structures\r\n",
        "sentences = []\r\n",
        "test_tags = []\r\n",
        "with open (\"pos_test.txt\",\"r\") as infile:\r\n",
        "    for line in infile:\r\n",
        "        #\r\n",
        "        # first tag is the start symbol\r\n",
        "        lasttag=[\"<s>\"]\r\n",
        "        #\r\n",
        "        # split line into word/tag pairs\r\n",
        "        #\r\n",
        "\r\n",
        "        # Start new word and tag list\r\n",
        "        words = []\r\n",
        "        sentence_tags = []\r\n",
        "        for wordtag in line.rstrip().split(\" \"):\r\n",
        "            if wordtag == \"\":\r\n",
        "                continue\r\n",
        "            # note that you might have escaped slashes\r\n",
        "            # 1\\/2/CD means \"1/2\" \"CD\"\r\n",
        "            # keep 1/2 as 1\\/2 \r\n",
        "            parts=wordtag.split(\"/\")\r\n",
        "            tag=parts.pop()\r\n",
        "            word=\"/\".join(parts)\r\n",
        "            #\r\n",
        "\r\n",
        "            tag_parts = tag.split(\"|\")\r\n",
        "\r\n",
        "            # Add word and tag\r\n",
        "            words.append(word)\r\n",
        "            sentence_tags.append(tag_parts)\r\n",
        "\r\n",
        "            lasttag=tag_parts\r\n",
        "\r\n",
        "        # Add new sentence and its corresponding tags\r\n",
        "        sentences.append(words)\r\n",
        "        test_tags.append(sentence_tags)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKsrxZA0a4rL"
      },
      "source": [
        "The above block of code reads in the test data and processes it. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umE-Pv5HJJSS"
      },
      "source": [
        "# Compute log probabilities\r\n",
        "tag_given_tag_probs = dict()\r\n",
        "word_given_tag_probs = dict()\r\n",
        "\r\n",
        "for tag, counts in tag_given_tag_counts.items():\r\n",
        "  tag_given_tag_probs[tag] = dict()\r\n",
        "\r\n",
        "  # Compute how many tags led to current tag\r\n",
        "  csum = sum(counts.values())\r\n",
        "  for element in counts:\r\n",
        "    tag_given_tag_probs[tag][element] = math.log(counts[element] / csum)\r\n",
        "\r\n",
        "\r\n",
        "for tag, counts in word_given_tag_counts.items():\r\n",
        "  word_given_tag_probs[tag] = dict()\r\n",
        "\r\n",
        "  # Compute how many words led to current tag \r\n",
        "  csum = sum(counts.values())\r\n",
        "  for element in counts:\r\n",
        "    word_given_tag_probs[tag][element] = math.log(counts[element] / csum)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnUIbOKabC7M"
      },
      "source": [
        "The above block of code computes the probabilities given the training data. We compute the observed probability of a tag given the previous tag, and the observed probability of a word given a tag. The log of these probabilities was taken to avoid underflow. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnA9YWsjt5DX"
      },
      "source": [
        "# Create probability matrices \r\n",
        "\r\n",
        "# Set value for missing values, because we cannot take log of zero\r\n",
        "absent_prob = math.log(.0001)\r\n",
        "\r\n",
        "tag_given_tag_probs_mat = np.ones((len(tags), len(tags))) * absent_prob\r\n",
        "word_given_tag_probs_mat = np.ones((len(tags), len(unique_words))) * absent_prob\r\n",
        "\r\n",
        "# Insert probabilities\r\n",
        "for i in range(len(tags)):\r\n",
        "  for j in range(len(tags)):\r\n",
        "    if tags[j] in tag_given_tag_probs[tags[i]]:\r\n",
        "      tag_given_tag_probs_mat[i, j] = tag_given_tag_probs[tags[i]][tags[j]]\r\n",
        "\r\n",
        "for j in range(len(tags)):\r\n",
        "  for t in range(len(unique_words)):\r\n",
        "    if unique_words[t] in word_given_tag_probs[tags[j]]:\r\n",
        "      word_given_tag_probs_mat[j, t] = word_given_tag_probs[tags[j]][unique_words[t]]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0v1pMQFbYM7"
      },
      "source": [
        "The above block of code creates matrices to store the transition probabilities and emission probabilities, based on the training data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h76CXa5uGDzl"
      },
      "source": [
        "# Create map from words to indices in unique_words list\r\n",
        "word_index = dict()\r\n",
        "\r\n",
        "for word in unique_words:\r\n",
        "  word_index[word] = unique_words.index(word)\r\n",
        "\r\n",
        "#Probability of most frequent tag\r\n",
        "most_frequent_prob = np.log(np.max(list(tag_count.values())) / np.sum(list(tag_count.values())))\r\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85s1XyZIbvhT"
      },
      "source": [
        "The above block of code maps words to an integer ID. The probability of the most frequent tag is calculated as well. If we encounter a word that we don't have a count for, we assume that it belongs to the most frequently encountered tag. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtKx-BMuONHD"
      },
      "source": [
        "# Viterbi algorithm\r\n",
        "def viterbi(obs, tags, word_index, word_given_tag_probs_mat, tag_given_tag_probs_mat, most_frequent_prob):\r\n",
        "  n = len(tags)\r\n",
        "  t = len(obs)\r\n",
        "\r\n",
        "  # Compute priors\r\n",
        "  priors = np.zeros((n))\r\n",
        "  den = t + tag_count['<s>']\r\n",
        "\r\n",
        "  for i in range(n):\r\n",
        "    priors[i] = math.log(tag_count[tags[i]] / den)\r\n",
        "\r\n",
        "  # Initialization step\r\n",
        "  viterbi = np.zeros((n, t))\r\n",
        "  backpointers = np.zeros((n, t))\r\n",
        "\r\n",
        "  for i in range(n):\r\n",
        "    if obs[0] in word_index.keys():\r\n",
        "      viterbi[i, 0] = priors[i] + word_given_tag_probs_mat[i, word_index[obs[0]]]\r\n",
        "    else:\r\n",
        "      viterbi[i, 0] = priors[i] + most_frequent_prob\r\n",
        "\r\n",
        "  # Recursive step\r\n",
        "  for timestep in range(1, t):\r\n",
        "    for state in range(n):\r\n",
        "      if obs[timestep] in word_index.keys():\r\n",
        "        temp = viterbi[:, timestep - 1] + tag_given_tag_probs_mat[:, state] + word_given_tag_probs_mat[state, word_index[obs[timestep]]]\r\n",
        "      else:\r\n",
        "        temp = viterbi[:, timestep - 1] + tag_given_tag_probs_mat[:, state] + most_frequent_prob\r\n",
        "\r\n",
        "      viterbi[state, timestep] = np.max(temp) \r\n",
        "      backpointers[state, timestep - 1] = int(np.argmax(temp))\r\n",
        "\r\n",
        "  # Termination\r\n",
        "  best_path_prob = np.max(viterbi[:, t - 1])\r\n",
        "  best_path_pointer = np.argmax(viterbi[:, t - 1])\r\n",
        "\r\n",
        "  best_path = np.ones(t)\r\n",
        "  best_path[-1] = best_path_pointer\r\n",
        "\r\n",
        "  # Backtracking\r\n",
        "  for timestep in range(t - 2, -1, -1):\r\n",
        "    best_path[timestep] = (int(backpointers[int(best_path[timestep + 1]), timestep]))\r\n",
        "\r\n",
        "  return best_path"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNc_Fj0wc-RO"
      },
      "source": [
        "The above block of code contains an implementation of the Viterbi algorithm, used to find the most likely tags for a sentence given the sentence itself. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAUlge_44K9q"
      },
      "source": [
        "# Accuracy function\r\n",
        "def accuracy(result, expected):\r\n",
        "  count = 0\r\n",
        "  for i in range(len(result)):\r\n",
        "    # Check if predicted tag is one of the acceptable tags\r\n",
        "    if int(result[i]) in expected[i]:\r\n",
        "      count += 1\r\n",
        "\r\n",
        "  acc = count / len(result)\r\n",
        "  return acc"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7E7YEaDydI92"
      },
      "source": [
        "The above block of code calculates the accuracy of results given the expected value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3owfiwIy6ird",
        "outputId": "295d488f-988c-4dcb-94ea-3d30b8eda439"
      },
      "source": [
        "avg_acc = 0\r\n",
        "\r\n",
        "# Run Viterbi algorithm for all sentences in the test dataset\r\n",
        "for i in range(len(sentences)):\r\n",
        "  path = viterbi(sentences[i], tags, word_index, word_given_tag_probs_mat, tag_given_tag_probs_mat, most_frequent_prob)\r\n",
        "  expected = []\r\n",
        "  for tag in test_tags[i]:\r\n",
        "    tag_pos = []\r\n",
        "    for tag_part in tag:\r\n",
        "      tag_pos.append(tags.index(tag_part))\r\n",
        "    expected.append(tag_pos)\r\n",
        "\r\n",
        "  avg_acc += accuracy(path, expected)\r\n",
        "\r\n",
        "avg_acc /= len(sentences)\r\n",
        "print(\"Average Accuracy: \" + str(format(avg_acc, \".3f\")))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Accuracy: 0.866\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNka18UjdS6D"
      },
      "source": [
        "The Viterbi algorithm was run for every sentence in the test dataset. Note that if the sentence has a word with more than one possible correct tag, if the predicted tag matches any of the potential tags, it was treated as correct. The average accuracy over every sentence in the test dataset was approximately 86.6%. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlEeH7h51Bml"
      },
      "source": [
        "# Extension 1: Forward-Backward\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRIn38qkeTHz"
      },
      "source": [
        "Forward-backward implementation for icecream\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KtZYBa15-WN"
      },
      "source": [
        "# Set up according to lab doc, not working yet\r\n",
        "\r\n",
        "train_sentences = []\r\n",
        "\r\n",
        "# Create map from words to indices in unique_words list\r\n",
        "word_index = dict()\r\n",
        "\r\n",
        "for word in unique_words:\r\n",
        "  word_index[word] = unique_words.index(word)\r\n",
        "\r\n",
        "with open (\"pos_train.txt\",\"r\") as infile:\r\n",
        "    for line in infile:\r\n",
        "        #\r\n",
        "        # first tag is the start symbol\r\n",
        "        lasttag=\"<s>\"\r\n",
        "        #\r\n",
        "        # split line into word/tag pairs\r\n",
        "        #\r\n",
        "\r\n",
        "        sentence = []\r\n",
        "        for wordtag in line.rstrip().split(\" \"):\r\n",
        "            if wordtag == \"\":\r\n",
        "                continue\r\n",
        "            # note that you might have escaped slashes\r\n",
        "            # 1\\/2/CD means \"1/2\" \"CD\"\r\n",
        "            # keep 1/2 as 1\\/2 \r\n",
        "            parts=wordtag.split(\"/\")\r\n",
        "            tag=parts.pop()\r\n",
        "            word=\"/\".join(parts)\r\n",
        "            \r\n",
        "            sentence.append(word_index[word])\r\n",
        "\r\n",
        "        train_sentences.append(sentence)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gC6DyEHfeUp"
      },
      "source": [
        "The above block of code reads in the training data and processes it for the purposes of the forward-backward algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UInaGczzz5Pj"
      },
      "source": [
        "def forward_backward_log(obs,prior,A,omega,B):\r\n",
        "  obs=np.reshape(obs,(-1))\r\n",
        "  T=obs.shape[0]\r\n",
        "  S=A.shape[0]\r\n",
        "  O=B.shape[1]\r\n",
        "\r\n",
        "  #Expectation\r\n",
        "  #Forward\r\n",
        "  alpha=np.zeros((T,S),dtype='double')\r\n",
        "\r\n",
        "  alpha[0,:]=np.reshape(prior,(1,-1)) + np.transpose(B[:,obs[0]])\r\n",
        "  for i in range(1,T):\r\n",
        "    #See Viterbi impl. for what is happening here\r\n",
        "    aa=np.reshape(B[:,obs[i]],(1,-1)) + A + np.reshape(alpha[i-1,:],(-1,1))\r\n",
        "    #Marginalize over all preceding possibilities\r\n",
        "    alpha[i,:]=np.log(np.sum(np.exp(aa),axis=0))\r\n",
        "\r\n",
        "  #Backward\r\n",
        "  beta=np.zeros((T,S),dtype='double')\r\n",
        "  beta[T-1,:]=np.reshape(omega,(1,-1))\r\n",
        "  for i in range(T-2,-1,-1):\r\n",
        "    #For each current state, what if it came before each possible succeeding state\r\n",
        "    #So matrix with col for current state, row for succ state\r\n",
        "    bb=np.reshape(B[:,obs[i+1]],(1,-1)) + A + np.reshape(beta[i+1,:],(1,-1))\r\n",
        "    #Marginalize over all possible succeeding states\r\n",
        "    beta[i,:]=np.log(np.sum(np.exp(bb),axis=1))\r\n",
        "  alphabeta=alpha + beta\r\n",
        "  #probability that we passed through state s at time i given the entire sequence\r\n",
        "  p_state_at_i=alphabeta - np.reshape(np.log(np.sum(np.exp(alphabeta),axis=1)),(-1,1))\r\n",
        "  #Maximization\r\n",
        "  s1 = np.sum(np.exp(p_state_at_i),axis=0)\r\n",
        "  for i in range(len(s1)):\r\n",
        "    if s1[i] == 0:\r\n",
        "      s1[i] += 0.0001\r\n",
        "  exp_state_instances=np.log(s1)\r\n",
        "\r\n",
        "  #Observations\r\n",
        "  Bnew=np.zeros(B.shape,dtype='double')\r\n",
        "  for j in range(S):\r\n",
        "    for l in range(O):\r\n",
        "      s2 = np.sum(np.exp(p_state_at_i[obs==l,j]))\r\n",
        "      if s2 == 0:\r\n",
        "        s2 += 0.0001\r\n",
        "      #print(s2)\r\n",
        "      exp_state_obs_instances=np.log(s2)\r\n",
        "      Bnew[j,l]=exp_state_obs_instances - exp_state_instances[j]\r\n",
        "  #Transitions\r\n",
        "  Anew=np.zeros(A.shape,dtype='double')\r\n",
        "  for j in range(S):\r\n",
        "    for k in range(S):\r\n",
        "      #Expected instances where we transitioned from state j to k\r\n",
        "      Anew[j,k]=np.log(np.sum(np.exp( alpha[:-1,j] + A[j,k] + beta[1:,k] + B[k,obs[1:]] - np.log(np.sum(np.exp(alphabeta[1:,:]),axis=1)) )))\r\n",
        "  Anew=Anew - np.reshape(exp_state_instances,(-1,1))\r\n",
        "  priorNew=p_state_at_i[0,:]\r\n",
        "  #How likely was state at end vs total instances of that state\r\n",
        "  omegaNew=p_state_at_i[-1,:] - exp_state_instances\r\n",
        "\r\n",
        "  return priorNew,Anew,omegaNew,Bnew"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lF4ViivegSVU"
      },
      "source": [
        "The above block of code is an implementation of the forward-backward algorithm, but uses log probabilities to prevent underflow issues. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ayqnVYDOgPD1",
        "outputId": "7f7c6eca-b707-49f1-c25b-7ed4d1881ce8"
      },
      "source": [
        "A=np.array([[0.8,0.1],[0.1,0.8]],dtype='double') #/(0.8+0.1)\r\n",
        "priors=np.array([0.5,0.5],dtype='double')\r\n",
        "omega=np.array([0.1,0.1],dtype='double')\r\n",
        "B=np.array([[0.7,0.2,0.1],[0.1,0.2,0.7]],dtype='double')\r\n",
        "obs=np.array([2,3,3,2,3,2,3,2,2,3,1,3,3,1,1,1,2,1,1,1,3,1,2,1,1,1,2,3,3,2,3,2,2],dtype='int')-1\r\n",
        "\r\n",
        "A = np.log(A)\r\n",
        "piors = np.log(priors)\r\n",
        "omega = np.log(omega)\r\n",
        "B = np.log(B)\r\n",
        "\r\n",
        "for iter in range(10):\r\n",
        "  priors,A,omega,B=forward_backward_log(obs,priors,A,omega,B)\r\n",
        "  display('-------------','priors',np.exp(priors),'A',np.exp(A),'omega',np.exp(omega),'B',np.exp(B))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'-------------'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'priors'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([0.12905787, 0.87094213])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0.87574097, 0.1089602 ],\n",
              "       [0.09251703, 0.86515797]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'omega'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([0.01529883, 0.042325  ])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'B'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0.67650238, 0.21881944, 0.10467818],\n",
              "       [0.0583723 , 0.42508654, 0.51654116]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'-------------'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'priors'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([0.01205868, 0.98794132])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0.90403448, 0.09371516],\n",
              "       [0.0766856 , 0.87040169]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'omega'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([0.00225035, 0.0529127 ])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'B'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0.69697033, 0.17145936, 0.13157031],\n",
              "       [0.04025206, 0.46379924, 0.49594871]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'-------------'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'priors'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([6.73487027e-04, 9.99326513e-01])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0.91905679, 0.08079954],\n",
              "       [0.07141208, 0.87166251]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'omega'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([0.00014367, 0.05692541])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'B'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0.6812583 , 0.15671837, 0.16202333],\n",
              "       [0.02621168, 0.48923557, 0.48455275]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'-------------'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'priors'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([3.07500696e-05, 9.99969250e-01])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0.92677132, 0.07322195],\n",
              "       [0.07065114, 0.86981516]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'omega'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([6.73288361e-06, 5.95337012e-02])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'B'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0.66322587, 0.15145523, 0.1853189 ],\n",
              "       [0.01504427, 0.50881415, 0.47614158]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'-------------'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'priors'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([1.28959501e-06, 9.99998710e-01])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0.93058153, 0.06941819],\n",
              "       [0.07098919, 0.86771935]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'omega'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([2.81871239e-07, 6.12914654e-02])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'B'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0.65175381, 0.14938538, 0.19886082],\n",
              "       [0.00770768, 0.52144364, 0.47084868]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'-------------'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'priors'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([5.21792564e-08, 9.99999948e-01])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0.93234929, 0.0676507 ],\n",
              "       [0.07137633, 0.86634879]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'omega'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([1.12940027e-08, 6.22748797e-02])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'B'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0.64577239, 0.1485875 , 0.20564011],\n",
              "       [0.00368781, 0.52825338, 0.46805881]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'-------------'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'priors'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([2.08071882e-09, 9.99999998e-01])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0.93314324, 0.06685676],\n",
              "       [0.07162025, 0.86561462]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'omega'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([4.44880238e-10, 6.27651271e-02])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'B'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0.6429051 , 0.14828066, 0.20881423],\n",
              "       [0.00170482, 0.53157086, 0.46672432]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'-------------'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'priors'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([8.24852983e-11, 1.00000000e+00])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0.93349619, 0.06650381],\n",
              "       [0.07174901, 0.86525491]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'omega'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([1.74074001e-11, 6.29960786e-02])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'B'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0.64157955, 0.14815894, 0.21026152],\n",
              "       [0.00077556, 0.53311254, 0.4661119 ]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'-------------'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'priors'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([3.26206409e-12, 1.00000000e+00])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0.93365298, 0.06634702],\n",
              "       [0.07181189, 0.86508605]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'omega'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([6.79283302e-13, 6.31020591e-02])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'B'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[6.40976479e-01, 1.48108622e-01, 2.10914899e-01],\n",
              "       [3.50252044e-04, 5.33814625e-01, 4.65835123e-01]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'-------------'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'priors'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([1.2887471e-13, 1.0000000e+00])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0.93372279, 0.06627721],\n",
              "       [0.07184143, 0.86500846]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'omega'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([2.64775193e-14, 6.31501113e-02])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'B'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[6.40704102e-01, 1.48087101e-01, 2.11208797e-01],\n",
              "       [1.57659441e-04, 5.34131667e-01, 4.65710673e-01]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9il7FAjBhO-M"
      },
      "source": [
        "The above block of code runs the forward-backward algorithm on Eisner's ice cream data for 10 iterations. The results for prior, posterior, transition, and emission probabilities match what was calculated by the Eisner ice cream spreadsheet after 10 iterations of the forward-backward algorithm. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keEowvbm1ddd"
      },
      "source": [
        "# Compute log probabilities\r\n",
        "tag_given_tag_probs = dict()\r\n",
        "word_given_tag_probs = dict()\r\n",
        "\r\n",
        "for tag, counts in tag_given_tag_counts.items():\r\n",
        "  tag_given_tag_probs[tag] = dict()\r\n",
        "\r\n",
        "  # Compute how many tags led to current tag\r\n",
        "  csum = len(counts)\r\n",
        "  for element in counts:\r\n",
        "    tag_given_tag_probs[tag][element] = math.log(1 / csum)\r\n",
        "\r\n",
        "for tag, counts in word_given_tag_counts.items():\r\n",
        "  word_given_tag_probs[tag] = dict()\r\n",
        "\r\n",
        "  # Compute how many words led to current tag \r\n",
        "  csum = len(counts)\r\n",
        "  for element in counts:\r\n",
        "    word_given_tag_probs[tag][element] = math.log(1 / csum)\r\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbfn--IEiHlU"
      },
      "source": [
        "The above block of code calculates the probabilities needed for the forward-backward algorithm. The log of the probabilities was taken to avoid underflow issues. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQdjn8QH1dmp"
      },
      "source": [
        "# Create probability matrices \r\n",
        "\r\n",
        "# Set value for missing values\r\n",
        "absent_prob = math.log(.0001)\r\n",
        "\r\n",
        "tag_given_tag_probs_mat = np.ones((len(tags), len(tags))) * absent_prob\r\n",
        "word_given_tag_probs_mat = np.ones((len(tags), len(unique_words))) * absent_prob\r\n",
        "\r\n",
        "# Insert probabilities\r\n",
        "for i in range(len(tags)):\r\n",
        "  for j in range(len(tags)):\r\n",
        "    if tags[j] in tag_given_tag_probs[tags[i]]:\r\n",
        "      tag_given_tag_probs_mat[i, j] = tag_given_tag_probs[tags[i]][tags[j]]\r\n",
        "\r\n",
        "for j in range(len(tags)):\r\n",
        "  for t in range(len(unique_words)):\r\n",
        "    if unique_words[t] in word_given_tag_probs[tags[j]]:\r\n",
        "      word_given_tag_probs_mat[j, t] = word_given_tag_probs[tags[j]][unique_words[t]]\r\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IFGKG_viQhK"
      },
      "source": [
        "The above block of code creates matrices for the transition and emission probabilities, specifically for use with the forward-backward algorithm. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apLXSceh1-PU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c99373f3-f6e1-4afe-dbe9-9f0914e2299e"
      },
      "source": [
        "#Initialize priors and omega\r\n",
        "priors = np.ones(len(tags)) * (1 / len(tags))\r\n",
        "omega = np.ones(len(tags)) * (1 / len(tags))\r\n",
        "\r\n",
        "#Take log of priors and omega\r\n",
        "priors = np.log(priors)\r\n",
        "omega = np.log(omega)\r\n",
        "\r\n",
        "num_iterations = 2\r\n",
        "max_length = 10\r\n",
        "num_sentences = 5\r\n",
        "\r\n",
        "dev_sentences = []\r\n",
        "\r\n",
        "for sentence in train_sentences:\r\n",
        "  if len(sentence) < max_length:\r\n",
        "    dev_sentences.append(sentence)\r\n",
        "\r\n",
        "dev_sentences = dev_sentences[:num_sentences]\r\n",
        "\r\n",
        "\r\n",
        "for i in range(num_iterations):\r\n",
        "  print(\"Iteration: \" + str(i))\r\n",
        "  for sentence in range(len(dev_sentences)):\r\n",
        "    priors, tag_given_tag_probs_mat, omega, word_given_tag_probs_mat = forward_backward_log(dev_sentences[sentence], priors, tag_given_tag_probs_mat, omega, word_given_tag_probs_mat)\r\n",
        "  display('-------------','priors',priors,'A',tag_given_tag_probs_mat,'omega',omega,'B',word_given_tag_probs_mat)\r\n",
        "  print()\r\n",
        "\r\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'-------------'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'priors'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([ -4.44039364,  -4.64131393,  -6.1129621 ,  -4.36106187,\n",
              "        -6.18668733,  -5.02728633,  -4.33937428,  -8.67299699,\n",
              "        -4.65596366,  -4.3944729 , -36.30361411,  -4.7002295 ,\n",
              "        -4.6883934 ,  -3.09104157,  -4.55847192,  -4.63421409,\n",
              "        -3.39981009,  -4.61959765,  -4.70646735,  -4.91905084,\n",
              "        -2.45224108,  -4.46630857,  -7.56563207,  -4.74597764,\n",
              "        -3.91181996,  -2.91311758,  -2.17360156,  -4.33838988,\n",
              "        -4.61230721,  -4.78336425,  -4.88618   ,  -4.63874091,\n",
              "        -4.03501543,  -4.97468878,  -4.31849089,  -3.06015708,\n",
              "        -3.04146613,  -5.318646  ,  -1.76806949,  -5.52581949,\n",
              "        -4.92806698, -10.49780354,  -2.63042743,  -5.93494447,\n",
              "        -3.24745686])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[ -4.37045166,  -6.7571102 ,  -5.73277599, ...,  -3.83824182,\n",
              "         -7.95419319, -11.63134813],\n",
              "       [ -4.09671494,  -6.8763502 ,  -5.47198995, ...,  -9.45575823,\n",
              "         -2.07800675, -11.67846814],\n",
              "       [ -4.56355671,  -8.48057154,  -5.91184604, ...,  -5.5958806 ,\n",
              "         -8.02364684, -13.39571853],\n",
              "       ...,\n",
              "       [ -2.3040037 ,  -9.6707423 ,  -3.70121955, ...,  -6.72823878,\n",
              "         -8.06959903,  -9.03031088],\n",
              "       [ -9.31728813,  -4.54067693, -10.65943779, ...,  -9.08666966,\n",
              "         -8.19774106, -11.56137155],\n",
              "       [ -8.13023834,  -0.48382526,  -1.01225504, ...,  -6.05832746,\n",
              "         -6.68877356,  -8.26290509]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'omega'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([-2.00916845e+01, -1.75390483e+01, -1.60005669e+01, -1.97465534e+01,\n",
              "       -1.60837880e+01, -2.08312844e+01, -2.05378097e+01, -2.71758898e+01,\n",
              "       -1.87736853e+01, -1.99468179e+01, -1.56795104e-05, -2.03098368e+01,\n",
              "       -2.03035013e+01, -2.15446980e+01, -2.05113447e+01, -1.98864401e+01,\n",
              "       -2.41949082e+01, -2.03017355e+01, -2.03574884e+01, -2.18364526e+01,\n",
              "       -2.49299702e+01, -2.04492049e+01, -1.96165968e+01, -2.12252524e+01,\n",
              "       -2.45363204e+01, -2.08167346e+01, -2.80725250e+01, -2.13047557e+01,\n",
              "       -2.23395541e+01, -1.94797757e+01, -2.06413852e+01, -2.14392165e+01,\n",
              "       -2.35101506e+01, -1.53499478e+01, -2.16460862e+01, -2.23667923e+01,\n",
              "       -2.16604469e+01, -2.04382189e+01, -3.46252799e+01, -2.29816983e+01,\n",
              "       -2.30618356e+01, -2.48148254e+01, -2.55110002e+01, -2.24113802e+01,\n",
              "       -2.24216114e+01])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'B'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[-6.33798018, -6.33798018, -6.33798018, ..., -6.33798018,\n",
              "        -6.33798018, -6.33798018],\n",
              "       [-6.07348571, -6.07348571, -6.07348571, ..., -6.07348571,\n",
              "        -6.07348571, -6.07348571],\n",
              "       [-6.01393224, -6.01393224, -6.01393224, ..., -6.01393224,\n",
              "        -6.01393224, -6.01393224],\n",
              "       ...,\n",
              "       [-6.67271902, -6.67271902, -6.67271902, ..., -6.67271902,\n",
              "        -6.67271902, -6.67271902],\n",
              "       [-5.91662824, -5.91662824, -5.91662824, ..., -5.91662824,\n",
              "        -5.91662824, -5.91662824],\n",
              "       [-6.03495367, -6.03495367, -6.03495367, ..., -6.03495367,\n",
              "        -6.03495367, -6.03495367]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'-------------'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'priors'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([  -5.69471052,   -4.99960301,   -7.84745385,   -6.01359845,\n",
              "         -9.57082135,   -9.04679701,   -6.03115597,  -11.31373714,\n",
              "         -6.20726273,   -5.33088395, -135.94256412,   -6.86690136,\n",
              "         -7.00474556,   -2.63080709,   -7.08463694,   -5.95806078,\n",
              "         -3.79889841,   -7.38446067,   -7.06842702,  -10.66067527,\n",
              "         -2.39111218,   -6.27024322,  -12.32495069,   -7.8350613 ,\n",
              "         -4.71186321,   -2.79108532,   -2.05916029,   -8.35140466,\n",
              "         -6.56451641,   -6.71242315,   -8.39378737,   -8.61974722,\n",
              "         -6.20202711,   -4.25669983,   -6.75965153,   -2.57093999,\n",
              "         -2.45119067,  -14.05287796,   -2.3292579 ,  -17.40688702,\n",
              "         -8.99686537,  -26.59815903,   -1.9191572 ,   -8.17182391,\n",
              "         -1.85269784])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[ -5.15605036,  -9.40237364,  -6.59266612, ...,  -8.53325161,\n",
              "         -7.91803538, -18.77088417],\n",
              "       [ -4.4562124 , -10.25107518,  -6.20570756, ..., -14.06064435,\n",
              "         -2.36082394, -18.57639542],\n",
              "       [ -5.49748262, -15.03369539,  -7.09892355, ..., -14.09506426,\n",
              "         -8.22713569, -24.23950594],\n",
              "       ...,\n",
              "       [ -2.12945928,  -9.12487828,  -3.66537963, ...,  -7.28806668,\n",
              "         -8.19147232, -11.72576215],\n",
              "       [-10.87834682, -10.96660723, -12.43468262, ..., -17.64882663,\n",
              "         -8.90542659, -22.59533527],\n",
              "       [ -8.32265087,  -0.30190154,  -1.37434253, ...,  -6.9042715 ,\n",
              "         -7.30624014, -11.23662528]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'omega'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([-1.65471098e+02, -1.63495656e+02, -1.36074674e+02, -1.60598428e+02,\n",
              "       -1.32305851e+02, -1.66875289e+02, -1.68309371e+02, -2.31580775e+02,\n",
              "       -1.53151426e+02, -1.65338270e+02, -1.47646118e-10, -1.66525882e+02,\n",
              "       -1.65810389e+02, -1.91482911e+02, -1.66411946e+02, -1.64131861e+02,\n",
              "       -2.09920955e+02, -1.64463081e+02, -1.64603136e+02, -1.74756147e+02,\n",
              "       -2.27113886e+02, -1.65952540e+02, -1.56763444e+02, -1.71290502e+02,\n",
              "       -2.01754887e+02, -1.84432707e+02, -2.53632446e+02, -1.71002906e+02,\n",
              "       -1.81226023e+02, -1.58422465e+02, -1.66179622e+02, -1.72305208e+02,\n",
              "       -1.90390667e+02, -1.35030773e+02, -1.74892509e+02, -1.99354577e+02,\n",
              "       -1.91775020e+02, -1.62613387e+02, -3.22135016e+02, -1.82960926e+02,\n",
              "       -1.86011102e+02, -1.98009005e+02, -2.26568167e+02, -1.86469572e+02,\n",
              "       -2.15408402e+02])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'B'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[-6.29823521, -6.29823521, -6.29823521, ..., -6.29823521,\n",
              "        -6.29823521, -6.29823521],\n",
              "       [-7.20708374, -7.20708374, -7.20708374, ..., -7.20708374,\n",
              "        -7.20708374, -7.20708374],\n",
              "       [-6.45960525, -6.45960525, -6.45960525, ..., -6.45960525,\n",
              "        -6.45960525, -6.45960525],\n",
              "       ...,\n",
              "       [-7.29600264, -7.29600264, -7.29600264, ..., -7.29600264,\n",
              "        -7.29600264, -7.29600264],\n",
              "       [-6.41597654, -6.41597654, -6.41597654, ..., -6.41597654,\n",
              "        -6.41597654, -6.41597654],\n",
              "       [-7.35819134, -7.35819134, -7.35819134, ..., -7.35819134,\n",
              "        -7.35819134, -7.35819134]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzOEYbGZjEKQ"
      },
      "source": [
        "The above block of code uses the forward-backward algorithm to find updated probabilities for prior, posterior, transition, and emission regarding sentence tagging. Note that not many iterations were used, and that the training is done using a small subset of the training dataset. This is because the algorithm takes a long time to run. In future trials, this training should be allowed to run for the entire dataset for more iterations to produce more accurate results. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYYECAsbxD-v",
        "outputId": "bfa630af-48cf-4650-fe5c-99cf7c7ac105"
      },
      "source": [
        "avg_acc = 0\r\n",
        "\r\n",
        "# Run the Viterbi algorithm on the test set\r\n",
        "# Use the updated probabilities from the forward-backward algorithm\r\n",
        "for i in range(len(sentences)):\r\n",
        "  path = viterbi(sentences[i], tags, word_index, word_given_tag_probs_mat, tag_given_tag_probs_mat, most_frequent_prob)\r\n",
        "  expected = []\r\n",
        "  for tag in test_tags[i]:\r\n",
        "    tag_pos = []\r\n",
        "    for tag_part in tag:\r\n",
        "      tag_pos.append(tags.index(tag_part))\r\n",
        "    expected.append(tag_pos)\r\n",
        "\r\n",
        "  avg_acc += accuracy(path, expected)\r\n",
        "\r\n",
        "avg_acc /= len(sentences)\r\n",
        "print(\"Average Accuracy: \" + str(format(avg_acc, \".3f\")))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Accuracy: 0.052\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBGC5r47k6k8"
      },
      "source": [
        "The Viterbi algorithm was run for every sentence in the test dataset. Note that if the sentence has a word with more than one possible correct tag, if the predicted tag matches any of the potential tags, it was treated as correct. The average accuracy over every sentence in the test dataset was approximately 5.2%. This was significantly worse than the accuracy from the Viterbi algorithm alone in part 0. This is likely because the forward-backward algorithm was trained using few iterations and with a smaller dataset. More robust training would likely produce far better results. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Dm-abJiAiAY"
      },
      "source": [
        "# Extension 3: Case Insensitive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXO_j4WSAqSG"
      },
      "source": [
        "# Compute counts from train data\r\n",
        "\r\n",
        "# Initialize data structures\r\n",
        "tag_given_tag_counts=dict()\r\n",
        "word_given_tag_counts=dict()\r\n",
        "\r\n",
        "tag_count = dict({'<s>': 0})\r\n",
        "\r\n",
        "unique_words = set()\r\n",
        "\r\n",
        "with open (\"pos_train.txt\",\"r\") as infile:\r\n",
        "    for line in infile:\r\n",
        "        #\r\n",
        "        # first tag is the start symbol\r\n",
        "        lasttag=[\"<s>\"]\r\n",
        "\r\n",
        "        tag_count['<s>'] += 1\r\n",
        "        #\r\n",
        "        # split line into word/tag pairs\r\n",
        "        #\r\n",
        "        for wordtag in line.rstrip().split(\" \"):\r\n",
        "            if wordtag == \"\":\r\n",
        "                continue\r\n",
        "            # note that you might have escaped slashes\r\n",
        "            # 1\\/2/CD means \"1/2\" \"CD\"\r\n",
        "            # keep 1/2 as 1\\/2 \r\n",
        "            parts=wordtag.split(\"/\")\r\n",
        "            pre_tag=parts.pop()\r\n",
        "            word=\"/\".join(parts)\r\n",
        "\r\n",
        "            word = word.lower()\r\n",
        "            tag_parts = pre_tag.split(\"|\")\r\n",
        " \r\n",
        "            for tag in tag_parts:\r\n",
        "              #\r\n",
        "              # update counters\r\n",
        "              if tag not in word_given_tag_counts:\r\n",
        "                  word_given_tag_counts[tag]=Counter()\r\n",
        "\r\n",
        "              if tag not in tag_count:\r\n",
        "                tag_count[tag] = 0\r\n",
        "\r\n",
        "              tag_count[tag] += 1\r\n",
        "\r\n",
        "              word_given_tag_counts[tag][word]+=1\r\n",
        "\r\n",
        "            for prev_tag in lasttag:\r\n",
        "              if prev_tag not in tag_given_tag_counts:\r\n",
        "                  tag_given_tag_counts[prev_tag]=Counter()\r\n",
        "\r\n",
        "            # Update list of words \r\n",
        "            unique_words.add(word)\r\n",
        "\r\n",
        "            for tag in tag_parts:\r\n",
        "              for prev_tag in lasttag:\r\n",
        "                tag_given_tag_counts[prev_tag][tag]+=1\r\n",
        "\r\n",
        "\r\n",
        "            lasttag=tag_parts\r\n",
        "\r\n",
        "# Create lists for words and tags, start tag not included\r\n",
        "tags = list(word_given_tag_counts.keys())\r\n",
        "unique_words = list(unique_words)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHMk6LanlFza"
      },
      "source": [
        "The above block of code reads in and processes the training data just as in part 0, but makes every word lower case. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NgEvUThAujx"
      },
      "source": [
        "# Read in test data\r\n",
        "\r\n",
        "# Initialize data structures\r\n",
        "sentences = []\r\n",
        "test_tags = []\r\n",
        "with open (\"pos_test.txt\",\"r\") as infile:\r\n",
        "    for line in infile:\r\n",
        "        #\r\n",
        "        # first tag is the start symbol\r\n",
        "        lasttag=[\"<s>\"]\r\n",
        "        #\r\n",
        "        # split line into word/tag pairs\r\n",
        "        #\r\n",
        "\r\n",
        "        # Start new word and tag list\r\n",
        "        words = []\r\n",
        "        sentence_tags = []\r\n",
        "        for wordtag in line.rstrip().split(\" \"):\r\n",
        "            if wordtag == \"\":\r\n",
        "                continue\r\n",
        "            # note that you might have escaped slashes\r\n",
        "            # 1\\/2/CD means \"1/2\" \"CD\"\r\n",
        "            # keep 1/2 as 1\\/2 \r\n",
        "            parts=wordtag.split(\"/\")\r\n",
        "            tag=parts.pop()\r\n",
        "            word=\"/\".join(parts)\r\n",
        "            #\r\n",
        "            word = word.lower()\r\n",
        "            tag_parts = tag.split(\"|\")\r\n",
        "\r\n",
        "            # Add word and tag\r\n",
        "            words.append(word)\r\n",
        "            sentence_tags.append(tag_parts)\r\n",
        "\r\n",
        "            lasttag=tag_parts\r\n",
        "\r\n",
        "        # Add new sentence and its corresponding tags\r\n",
        "        sentences.append(words)\r\n",
        "        test_tags.append(sentence_tags)\r\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYcOkXeDlPqY"
      },
      "source": [
        "The above block of code reads in and processes the test data just as in part 0, but makes every word lower case. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqupnmaMBAkg"
      },
      "source": [
        "# Compute log probabilities\r\n",
        "tag_given_tag_probs = dict()\r\n",
        "word_given_tag_probs = dict()\r\n",
        "\r\n",
        "for tag, counts in tag_given_tag_counts.items():\r\n",
        "  tag_given_tag_probs[tag] = dict()\r\n",
        "\r\n",
        "  # Compute how many tags led to current tag\r\n",
        "  csum = sum(counts.values())\r\n",
        "  for element in counts:\r\n",
        "    tag_given_tag_probs[tag][element] = math.log(counts[element] / csum)\r\n",
        "\r\n",
        "for tag, counts in word_given_tag_counts.items():\r\n",
        "  word_given_tag_probs[tag] = dict()\r\n",
        "\r\n",
        "  # Compute how many words led to current tag \r\n",
        "  csum = sum(counts.values())\r\n",
        "  for element in counts:\r\n",
        "    word_given_tag_probs[tag][element] = math.log(counts[element] / csum)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H05HsNtWlSwh"
      },
      "source": [
        "The probabilities are recalculated after the case adjustment was made. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAj6vFCwBEsL"
      },
      "source": [
        "# Create probability matrices \r\n",
        "\r\n",
        "# Set value for missing values\r\n",
        "absent_prob = math.log(.0001)\r\n",
        "\r\n",
        "tag_given_tag_probs_mat = np.ones((len(tags), len(tags))) * absent_prob\r\n",
        "word_given_tag_probs_mat = np.ones((len(tags), len(unique_words))) * absent_prob\r\n",
        "\r\n",
        "# Insert probabilities\r\n",
        "for i in range(len(tags)):\r\n",
        "  for j in range(len(tags)):\r\n",
        "    if tags[j] in tag_given_tag_probs[tags[i]]:\r\n",
        "      tag_given_tag_probs_mat[i, j] = tag_given_tag_probs[tags[i]][tags[j]]\r\n",
        "\r\n",
        "for j in range(len(tags)):\r\n",
        "  for t in range(len(unique_words)):\r\n",
        "    if unique_words[t] in word_given_tag_probs[tags[j]]:\r\n",
        "      word_given_tag_probs_mat[j, t] = word_given_tag_probs[tags[j]][unique_words[t]]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vX0Y9P5lXLq"
      },
      "source": [
        "The transition and emission probability matrices are updated to reflect the case change, as well. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yxaBJkImIlL"
      },
      "source": [
        "# Create map from words to indices in unique_words list\r\n",
        "word_index = dict()\r\n",
        "\r\n",
        "for word in unique_words:\r\n",
        "  word_index[word] = unique_words.index(word)\r\n",
        "\r\n",
        "most_frequent_prob = np.log(np.max(list(tag_count.values())) / np.sum(list(tag_count.values())))\r\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wCT_LEBkJjl"
      },
      "source": [
        "The above block of code maps words to an integer ID. The probability of the most frequent tag is calculated as well. If we encounter a word that we don't have a count for, we assume that it belongs to the most frequently encountered tag."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrBoZntpBIeZ",
        "outputId": "6e0e7a59-b8fb-4025-8cb1-64f14f8d974e"
      },
      "source": [
        "avg_acc = 0\r\n",
        "\r\n",
        "# Run Viterbi algorithm on the lower case test dataset\r\n",
        "for i in range(len(sentences)):\r\n",
        "  path = viterbi(sentences[i], tags, word_index, word_given_tag_probs_mat, tag_given_tag_probs_mat, most_frequent_prob)\r\n",
        "  expected = []\r\n",
        "  for tag in test_tags[i]:\r\n",
        "    tag_pos = []\r\n",
        "    for tag_part in tag:\r\n",
        "      tag_pos.append(tags.index(tag_part))\r\n",
        "    expected.append(tag_pos)\r\n",
        "\r\n",
        "  avg_acc += accuracy(path, expected)\r\n",
        "\r\n",
        "avg_acc /= len(sentences)\r\n",
        "print(\"Average Accuracy: \" + str(format(avg_acc, \".3f\")))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Accuracy: 0.864\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miztC_1MlofV"
      },
      "source": [
        "The Viterbi algorithm was run for every sentence in the test dataset, but with every word being lower case. Note that if the sentence has a word with more than one possible correct tag, if the predicted tag matches any of the potential tags, it was treated as correct. The average accuracy over every sentence in the test dataset was approximately 86.4%. This was 0.2% lower than the accuracy when words were appropriately capitalized, as calculated in part 0. This indicates that word capitalization does not have a significant impact on sentence tagging. "
      ]
    }
  ]
}